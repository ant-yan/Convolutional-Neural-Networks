{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models as vision_models\n",
    "from sklearn.metrics import precision_score as calc_precision, recall_score as calc_recall\n",
    "\n",
    "# Configuration parameters\n",
    "bsz = 128\n",
    "num_epochs = 20\n",
    "lr_val = 0.001\n",
    "net_arch = \"resnet50\"\n",
    "\n",
    "def setup_loaders(bsz=128):\n",
    "    tr_trans = T.Compose([\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    te_trans = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=tr_trans)\n",
    "    dl_train = DataLoader(train_data, batch_size=bsz, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=te_trans)\n",
    "    dl_test = DataLoader(test_data, batch_size=bsz, shuffle=False, num_workers=2)\n",
    "\n",
    "    return dl_train, dl_test\n",
    "\n",
    "def build_model(arch):\n",
    "    if arch == \"resnet18\":\n",
    "        net = vision_models.resnet18(weights=vision_models.ResNet18_Weights.DEFAULT)\n",
    "        net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "    elif arch == \"resnet50\":\n",
    "        net = vision_models.resnet50(weights=vision_models.ResNet50_Weights.DEFAULT)\n",
    "        net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "    elif arch == \"vgg16\":\n",
    "        net = vision_models.vgg16(weights=vision_models.VGG16_Weights.DEFAULT)\n",
    "        net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Model architecture not supported.\")\n",
    "\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return net\n",
    "\n",
    "def run_training(net, loader_train, loader_test, epochs, lr):\n",
    "    dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(dev)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    lr_adjust = optim.lr_scheduler.StepLR(opt, step_size=5, gamma=0.1)\n",
    "\n",
    "    history_train, history_val, accuracy_val = [], [], []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        net.train()\n",
    "        tot_loss = 0.0\n",
    "\n",
    "        for imgs, lbls in loader_train:\n",
    "            imgs, lbls = imgs.to(dev), lbls.to(dev)\n",
    "            opt.zero_grad()\n",
    "            outs = net(imgs)\n",
    "            cost = loss_func(outs, lbls)\n",
    "            cost.backward()\n",
    "            opt.step()\n",
    "            tot_loss += cost.item()\n",
    "\n",
    "        history_train.append(tot_loss / len(loader_train))\n",
    "\n",
    "        net.eval()\n",
    "        correct_pred, total_samples = 0, 0\n",
    "        tot_val_loss = 0.0\n",
    "        pred_list, label_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls in loader_test:\n",
    "                imgs, lbls = imgs.to(dev), lbls.to(dev)\n",
    "                outs = net(imgs)\n",
    "                cost = loss_func(outs, lbls)\n",
    "                tot_val_loss += cost.item()\n",
    "                _, preds = torch.max(outs, 1)\n",
    "                total_samples += lbls.size(0)\n",
    "                correct_pred += (preds == lbls).sum().item()\n",
    "                pred_list.extend(preds.cpu().numpy())\n",
    "                label_list.extend(lbls.cpu().numpy())\n",
    "\n",
    "        history_val.append(tot_val_loss / len(loader_test))\n",
    "        epoch_acc = correct_pred / total_samples\n",
    "        accuracy_val.append(epoch_acc)\n",
    "\n",
    "        prc = calc_precision(label_list, pred_list, average='macro', zero_division=1)\n",
    "        rcl = calc_recall(label_list, pred_list, average='macro', zero_division=1)\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(net.state_dict(), \"optimal_model.pth\")\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} - Train Loss: {history_train[-1]:.4f}, Val Loss: {history_val[-1]:.4f}, \"\n",
    "              f\"Acc: {epoch_acc:.4f}, Precision: {prc:.4f}, Recall: {rcl:.4f}\")\n",
    "\n",
    "        lr_adjust.step()\n",
    "\n",
    "    return net, history_train, history_val, accuracy_val\n",
    "\n",
    "def display_stats(train_hist, val_hist, val_acc):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_hist, label='Training Loss')\n",
    "    plt.plot(val_hist, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss per Epoch')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.show()\n",
    "\n",
    "def store_model(net, file_path=\"final_cifar10_model.pth\"):\n",
    "    torch.save(net.state_dict(), file_path)\n",
    "    print(f\"Model saved at: {file_path}\")\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    loader_tr, loader_te = setup_loaders(bsz)\n",
    "    network = build_model(net_arch)\n",
    "    trained_net, loss_history, val_loss_history, acc_history = run_training(network, loader_tr, loader_te, num_epochs, lr_val)\n",
    "    display_stats(loss_history, val_loss_history, acc_history)\n",
    "    store_model(trained_net)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}